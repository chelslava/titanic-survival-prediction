"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç–∏ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤ –¢–∏—Ç–∞–Ω–∏–∫–∞.
–í–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É, –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π,
–æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏.
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import joblib
from typing import Tuple, Dict, Any

# –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from xgboost import XGBClassifier

# –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score
)

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã –≤—ã–≤–æ–¥–∞
warnings.filterwarnings('ignore')

class TitanicPredictor:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç–∏ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤ –¢–∏—Ç–∞–Ω–∏–∫–∞.
    –í–∫–ª—é—á–∞–µ—Ç –º–µ—Ç–æ–¥—ã –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∏ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞.
    """
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞"""
        self.df = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.best_model = None
        self.features = []
    
    def load_data(self, filepath: str = './data/train.csv') -> pd.DataFrame:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV —Ñ–∞–π–ª–∞
        
        Args:
            filepath: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏
            
        Returns:
            DataFrame —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        """
        try:
            self.df = pd.read_csv(filepath)
            print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ {filepath}")
            print(f"üìä –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {self.df.shape}")
            return self.df
        except FileNotFoundError:
            print(f"‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª {filepath} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
    
    def explore_data(self) -> None:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –±–∞–∑–æ–≤—ã–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"""
        if self.df is None:
            print("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –°–Ω–∞—á–∞–ª–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ load_data()")
            return
        
        print("=" * 50)
        print("üìä –ò–°–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•")
        print("=" * 50)
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
        print("\nüîç –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
        print(self.df.info())
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        print("\nüìà –û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(self.df.describe())
        
        # –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        print("\nüï≥Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
        missing_data = self.df.isnull().sum()
        missing_percent = (missing_data / len(self.df)) * 100
        missing_df = pd.DataFrame({
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': missing_data,
            '–ü—Ä–æ—Ü–µ–Ω—Ç': missing_percent
        })
        print(missing_df[missing_df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] > 0])
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        print("\nüéØ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (Survived):")
        survived_counts = self.df['Survived'].value_counts()
        print(f"–ù–µ –≤—ã–∂–∏–ª–æ: {survived_counts[0]} ({survived_counts[0]/len(self.df)*100:.1f}%)")
        print(f"–í—ã–∂–∏–ª–æ: {survived_counts[1]} ({survived_counts[1]/len(self.df)*100:.1f}%)")
    
    def visualize_data(self) -> None:
        """–°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö"""
        if self.df is None:
            print("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
            return
        
        plt.style.use('seaborn-v0_8')
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle('–ê–Ω–∞–ª–∏–∑ –≤—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç–∏ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤ –¢–∏—Ç–∞–Ω–∏–∫–∞', fontsize=16)
        
        # 1. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—ã–∂–∏–≤—à–∏—Ö
        sns.countplot(data=self.df, x='Survived', ax=axes[0, 0])
        axes[0, 0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—ã–∂–∏–≤—à–∏—Ö')
        axes[0, 0].set_xlabel('–í—ã–∂–∏–ª (0 = –ù–µ—Ç, 1 = –î–∞)')
        
        # 2. –í—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –ø–æ –ø–æ–ª—É
        sns.barplot(data=self.df, x='Sex', y='Survived', ax=axes[0, 1])
        axes[0, 1].set_title('–í—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –ø–æ –ø–æ–ª—É')
        
        # 3. –í—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å—É
        sns.barplot(data=self.df, x='Pclass', y='Survived', ax=axes[0, 2])
        axes[0, 2].set_title('–í—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å—É')
        
        # 4. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–æ–∑—Ä–∞—Å—Ç–∞
        sns.histplot(data=self.df, x='Age', hue='Survived', kde=True, ax=axes[1, 0])
        axes[1, 0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–æ–∑—Ä–∞—Å—Ç–∞')
        
        # 5. –í—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å—É –∏ –ø–æ–ª—É
        sns.barplot(data=self.df, x='Pclass', y='Survived', hue='Sex', ax=axes[1, 1])
        axes[1, 1].set_title('–í—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å—É –∏ –ø–æ–ª—É')
        
        # 6. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –±–∏–ª–µ—Ç–æ–≤
        sns.histplot(data=self.df, x='Fare', hue='Survived', kde=True, ax=axes[1, 2])
        axes[1, 2].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –±–∏–ª–µ—Ç–æ–≤')
        
        plt.tight_layout()
        plt.show()
    
    def preprocess_data(self) -> None:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö"""
        if self.df is None:
            print("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
            return
        
        print("üîß –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö...")
        
        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        print("  ‚Ä¢ –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤–æ–∑—Ä–∞—Å—Ç–∞ –º–µ–¥–∏–∞–Ω–æ–π")
        self.df['Age'] = self.df['Age'].fillna(self.df['Age'].median())
        
        print("  ‚Ä¢ –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ—Ä—Ç–∞ –ø–æ—Å–∞–¥–∫–∏ –º–æ–¥–æ–π")
        self.df['Embarked'] = self.df['Embarked'].fillna(self.df['Embarked'].mode()[0])
        
        print("  ‚Ä¢ –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –±–∏–ª–µ—Ç–∞ –º–µ–¥–∏–∞–Ω–æ–π")
        self.df['Fare'] = self.df['Fare'].fillna(self.df['Fare'].median())
        
        # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        print("  ‚Ä¢ –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–∞: male -> 0, female -> 1")
        self.df['Sex'] = self.df['Sex'].map({'male': 0, 'female': 1})
        
        print("  ‚Ä¢ One-hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Ä—Ç–∞ –ø–æ—Å–∞–¥–∫–∏")
        self.df = pd.get_dummies(self.df, columns=['Embarked'], drop_first=True)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        print("  ‚Ä¢ –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Å–µ–º—å–∏")
        self.df['FamilySize'] = self.df['SibSp'] + self.df['Parch']
        
        print("  ‚Ä¢ –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ –æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–∞")
        self.df['IsAlone'] = (self.df['FamilySize'] == 0).astype(int)
        
        print("  ‚Ä¢ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∏—Ç—É–ª–æ–≤ –∏–∑ –∏–º–µ–Ω")
        self.df['Title'] = self.df['Name'].str.extract(r',\s*([^\.]+)\.', expand=False)
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Ä–µ–¥–∫–∏—Ö —Ç–∏—Ç—É–ª–æ–≤
        title_counts = self.df['Title'].value_counts()
        rare_titles = title_counts[title_counts < 10].index
        self.df['Title'] = self.df['Title'].replace(rare_titles, 'Rare')
        
        # –£–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏—Ç—É–ª–æ–≤
        title_mapping = {
            'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs',
            'Lady': 'Royalty', 'Countess': 'Royalty', 'Dona': 'Royalty',
            'Capt': 'Officer', 'Col': 'Officer', 'Major': 'Officer',
            'Dr': 'Officer', 'Rev': 'Officer',
            'Don': 'Noble', 'Sir': 'Noble', 'Jonkheer': 'Noble'
        }
        self.df['Title'] = self.df['Title'].replace(title_mapping)
        
        # One-hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∏—Ç—É–ª–æ–≤
        self.df = pd.get_dummies(self.df, columns=['Title'], drop_first=True)
        
        print("  ‚Ä¢ –°–æ–∑–¥–∞–Ω–∏–µ –≤–æ–∑—Ä–∞—Å—Ç–Ω—ã—Ö –≥—Ä—É–ø–ø")
        self.df['AgeGroup'] = pd.cut(
            self.df['Age'], 
            bins=[0, 12, 18, 35, 60, 100], 
            labels=['Child', 'Teen', 'YoungAdult', 'Adult', 'Senior']
        )
        self.df = pd.get_dummies(self.df, columns=['AgeGroup'], drop_first=True)
        
        print("  ‚Ä¢ –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–∞—é—Ç—ã")
        self.df['HasCabin'] = self.df['Cabin'].notnull().astype(int)
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        print("  ‚Ä¢ –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        self.df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        title_features = [col for col in self.df.columns if col.startswith('Title_')]
        agegroup_features = [col for col in self.df.columns if col.startswith('AgeGroup_')]
        embarked_features = [col for col in self.df.columns if col.startswith('Embarked_')]
        
        self.features = [
            'Pclass', 'Sex', 'Age', 'Fare', 'FamilySize', 'IsAlone', 'HasCabin'
        ] + title_features + agegroup_features + embarked_features
        
        print(f"‚úÖ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ò—Ç–æ–≥–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(self.features)}")
    
    def prepare_train_test(self, test_size: float = 0.2, random_state: int = 42) -> None:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        
        Args:
            test_size: —Ä–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏
            random_state: –∑–µ—Ä–Ω–æ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏
        """
        if self.df is None:
            print("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã")
            return
        
        # –í—ã–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        X = self.df[self.features]
        y = self.df['Survived']
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state, stratify=y
        )
        
        print(f"üìä –î–∞–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–µ–Ω—ã:")
        print(f"  ‚Ä¢ –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {self.X_train.shape}")
        print(f"  ‚Ä¢ –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {self.X_test.shape}")
    
    def train_models(self) -> Dict[str, Any]:
        """
        –û–±—É—á–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ–±—É—á–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
        """
        if self.X_train is None:
            print("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return {}
        
        print("ü§ñ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
        
        models = {}
        
        # 1. –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
        print("  ‚Ä¢ –û–±—É—á–µ–Ω–∏–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏")
        lr = LogisticRegression(max_iter=1000, random_state=42)
        lr.fit(self.X_train, self.y_train)
        models['LogisticRegression'] = lr
        
        # 2. –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å
        print("  ‚Ä¢ –û–±—É—á–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞")
        rf = RandomForestClassifier(n_estimators=100, random_state=42)
        rf.fit(self.X_train, self.y_train)
        models['RandomForest'] = rf
        
        # 3. XGBoost
        print("  ‚Ä¢ –û–±—É—á–µ–Ω–∏–µ XGBoost")
        xgb = XGBClassifier(eval_metric='logloss', random_state=42)
        xgb.fit(self.X_train, self.y_train)
        models['XGBoost'] = xgb
        
        print("‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω—ã")
        return models
    
    def evaluate_models(self, models: Dict[str, Any]) -> pd.DataFrame:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        
        Args:
            models: —Å–ª–æ–≤–∞—Ä—å —Å –æ–±—É—á–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
            
        Returns:
            DataFrame —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        """
        if not models or self.X_test is None:
            print("‚ùå –ú–æ–¥–µ–ª–∏ –Ω–µ –æ–±—É—á–µ–Ω—ã –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã")
            return pd.DataFrame()
        
        print("üìä –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π...")
        
        results = []
        
        for name, model in models.items():
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            y_pred = model.predict(self.X_test)
            y_prob = model.predict_proba(self.X_test)[:, 1] if hasattr(model, 'predict_proba') else None
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            accuracy = accuracy_score(self.y_test, y_pred)
            precision = precision_score(self.y_test, y_pred)
            recall = recall_score(self.y_test, y_pred)
            f1 = f1_score(self.y_test, y_pred)
            roc_auc = roc_auc_score(self.y_test, y_prob) if y_prob is not None else None
            
            results.append({
                '–ú–æ–¥–µ–ª—å': name,
                'Accuracy': f"{accuracy:.4f}",
                'Precision': f"{precision:.4f}",
                'Recall': f"{recall:.4f}",
                'F1-Score': f"{f1:.4f}",
                'ROC-AUC': f"{roc_auc:.4f}" if roc_auc else "N/A"
            })
            
            print(f"  ‚Ä¢ {name}: Accuracy = {accuracy:.4f}")
        
        results_df = pd.DataFrame(results)
        return results_df
    
    def optimize_models(self) -> Dict[str, Any]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–µ–π
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
        """
        if self.X_train is None:
            print("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã")
            return {}
        
        print("‚öôÔ∏è –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")
        
        optimized_models = {}
        
        # –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
        print("  ‚Ä¢ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏")
        param_grid_lr = {
            'C': [0.01, 0.1, 1, 10],
            'penalty': ['l2'],
            'solver': ['lbfgs', 'liblinear']
        }
        
        grid_lr = GridSearchCV(
            LogisticRegression(max_iter=1000, random_state=42),
            param_grid_lr, cv=5, scoring='accuracy', n_jobs=-1
        )
        grid_lr.fit(self.X_train, self.y_train)
        optimized_models['LogisticRegression'] = grid_lr.best_estimator_
        print(f"    –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {grid_lr.best_params_}")
        
        # –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å
        print("  ‚Ä¢ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞")
        param_grid_rf = {
            'n_estimators': [100, 200],
            'max_depth': [4, 6, 8, None],
            'min_samples_split': [2, 5, 10]
        }
        
        grid_rf = GridSearchCV(
            RandomForestClassifier(random_state=42),
            param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1
        )
        grid_rf.fit(self.X_train, self.y_train)
        optimized_models['RandomForest'] = grid_rf.best_estimator_
        print(f"    –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {grid_rf.best_params_}")
        
        # XGBoost
        print("  ‚Ä¢ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è XGBoost")
        param_grid_xgb = {
            'n_estimators': [100, 200],
            'max_depth': [3, 5, 7],
            'learning_rate': [0.01, 0.1, 0.2]
        }
        
        grid_xgb = GridSearchCV(
            XGBClassifier(eval_metric='logloss', random_state=42),
            param_grid_xgb, cv=5, scoring='accuracy', n_jobs=-1
        )
        grid_xgb.fit(self.X_train, self.y_train)
        optimized_models['XGBoost'] = grid_xgb.best_estimator_
        print(f"    –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {grid_xgb.best_params_}")
        
        print("‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        return optimized_models
    
    def create_ensemble(self, models: Dict[str, Any]) -> VotingClassifier:
        """
        –°–æ–∑–¥–∞–µ—Ç –∞–Ω—Å–∞–º–±–ª—å –∏–∑ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π
        
        Args:
            models: —Å–ª–æ–≤–∞—Ä—å —Å –º–æ–¥–µ–ª—è–º–∏
            
        Returns:
            –û–±—É—á–µ–Ω–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å –º–æ–¥–µ–ª–µ–π
        """
        if not models or self.X_train is None:
            print("‚ùå –ú–æ–¥–µ–ª–∏ –Ω–µ –≥–æ—Ç–æ–≤—ã –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã")
            return None
        
        print("üé≠ –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π...")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è
        estimators = [(name.lower(), model) for name, model in models.items()]
        
        ensemble = VotingClassifier(
            estimators=estimators,
            voting='soft'  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è
        )
        
        # –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è
        ensemble.fit(self.X_train, self.y_train)
        
        print("‚úÖ –ê–Ω—Å–∞–º–±–ª—å —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –∏ –æ–±—É—á–µ–Ω")
        return ensemble
    
    def evaluate_final_model(self, model: Any) -> None:
        """
        –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
        
        Args:
            model: –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏
        """
        if model is None or self.X_test is None:
            print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –≥–æ—Ç–æ–≤–∞ –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã")
            return
        
        print("üèÜ –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò")
        print("=" * 40)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        y_pred = model.predict(self.X_test)
        y_prob = model.predict_proba(self.X_test)[:, 1]
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        accuracy = accuracy_score(self.y_test, y_pred)
        precision = precision_score(self.y_test, y_pred)
        recall = recall_score(self.y_test, y_pred)
        f1 = f1_score(self.y_test, y_pred)
        roc_auc = roc_auc_score(self.y_test, y_prob)
        
        print(f"üìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:")
        print(f"  ‚Ä¢ Accuracy:  {accuracy:.4f}")
        print(f"  ‚Ä¢ Precision: {precision:.4f}")
        print(f"  ‚Ä¢ Recall:    {recall:.4f}")
        print(f"  ‚Ä¢ F1-Score:  {f1:.4f}")
        print(f"  ‚Ä¢ ROC-AUC:   {roc_auc:.4f}")
        
        # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
        print(f"\nüîç –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
        cm = confusion_matrix(self.y_test, y_pred)
        print("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ:   –ù–µ –≤—ã–∂–∏–ª  –í—ã–∂–∏–ª")
        print(f"–ù–µ –≤—ã–∂–∏–ª         {cm[0,0]:6d}   {cm[0,1]:5d}")
        print(f"–í—ã–∂–∏–ª            {cm[1,0]:6d}   {cm[1,1]:5d}")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        print(f"\nüìÑ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç:")
        print(classification_report(self.y_test, y_pred, 
                                  target_names=['–ù–µ –≤—ã–∂–∏–ª', '–í—ã–∂–∏–ª']))
        
        self.best_model = model
    
    def save_model(self, model: Any, filepath: str = '../models/titanic_model.pkl') -> None:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        
        Args:
            model: –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            filepath: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        try:
            joblib.dump(model, filepath)
            print(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {filepath}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
    
    def run_full_pipeline(self, data_path: str = '../data/train.csv') -> None:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            data_path: –ø—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º
        """
        print("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –ü–ê–ô–ü–õ–ê–ô–ù–ê –ú–ê–®–ò–ù–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
        print("=" * 60)
        
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.load_data(data_path)
        if self.df is None:
            return
        
        # 2. –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
        self.explore_data()
        
        # 3. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        self.visualize_data()
        
        # 4. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        self.preprocess_data()
        
        # 5. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.prepare_train_test()
        
        # 6. –û–±—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
        basic_models = self.train_models()
        
        # 7. –û—Ü–µ–Ω–∫–∞ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
        basic_results = self.evaluate_models(basic_models)
        print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π:")
        print(basic_results.to_string(index=False))
        
        # 8. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
        optimized_models = self.optimize_models()
        
        # 9. –û—Ü–µ–Ω–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        optimized_results = self.evaluate_models(optimized_models)
        print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:")
        print(optimized_results.to_string(index=False))
        
        # 10. –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è
        ensemble = self.create_ensemble(optimized_models)
        
        # 11. –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        self.evaluate_final_model(ensemble)
        
        # 12. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.save_model(ensemble)
        
        print("\nüéâ –ü–ê–ô–ü–õ–ê–ô–ù –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞"""
    # –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞
    predictor = TitanicPredictor()
    
    # –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞
    predictor.run_full_pipeline('../data/train.csv')


if __name__ == "__main__":
    main()